# üìä Gu√≠a Completa del Sistema de Logging en Excel

Esta gu√≠a explica c√≥mo usar el sistema de registro de resultados en Excel para DeepLabScan, que permite guardar y comparar resultados de entrenamientos, evaluaciones y predicciones.

## üéØ Caracter√≠sticas Principales

- ‚úÖ **Guardado autom√°tico** de resultados en Excel
- ‚úÖ **4 hojas organizadas**: Resumen, Training, Evaluation, Prediction
- ‚úÖ **Comparaci√≥n f√°cil** entre experimentos
- ‚úÖ **Identificaci√≥n autom√°tica** del mejor modelo
- ‚úÖ **Formato profesional** con colores y columnas ajustadas
- ‚úÖ **Exportaci√≥n a CSV** para an√°lisis adicional

## üìÅ Estructura de Archivos

```
DeepLabScan/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Script de entrenamiento (con Excel logging)
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # Script de evaluaci√≥n (con Excel logging)
‚îÇ   ‚îú‚îÄ‚îÄ predict.py            # Script de predicci√≥n (con Excel logging)
‚îÇ   ‚îú‚îÄ‚îÄ excel_logger.py       # M√≥dulo de logging
‚îÇ   ‚îú‚îÄ‚îÄ view_results.py       # Visualizaci√≥n de resultados
‚îÇ   ‚îî‚îÄ‚îÄ test_excel_logger.py  # Script de prueba
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_results.xlsx  # Archivo principal con todos los resultados
‚îÇ   ‚îî‚îÄ‚îÄ README.md               # Documentaci√≥n del sistema
‚îî‚îÄ‚îÄ EXCEL_LOGGING_GUIDE.md      # Esta gu√≠a
```

## üöÄ Inicio R√°pido

### 1. Instalar Dependencias

```bash
pip install pandas openpyxl
```

O instalar todo el proyecto:

```bash
pip install -r requirements.txt
```

### 2. Entrenar y Guardar Resultados

```bash
# Entrenamiento b√°sico (guarda autom√°ticamente en Excel)
python scripts/train.py --data-dir data/raw --epochs 15

# Entrenamiento con nombre personalizado y notas
python scripts/train.py \
    --data-dir data/raw \
    --model yolo11n.pt \
    --epochs 30 \
    --name "exp_yolo11n_v1" \
    --notes "Primer entrenamiento con yolo11n"
```

### 3. Evaluar y Guardar Resultados

```bash
# Evaluaci√≥n b√°sica
python scripts/evaluate.py --weights runs/detect/train/weights/best.pt

# Evaluaci√≥n con nombre personalizado
python scripts/evaluate.py \
    --weights runs/detect/train/weights/best.pt \
    --exp-name "eval_modelo_v1" \
    --notes "Evaluaci√≥n inicial del modelo"
```

### 4. Predecir y Guardar Resultados

```bash
# Predicci√≥n b√°sica
python scripts/predict.py \
    --weights runs/detect/train/weights/best.pt \
    --source test_image.jpg

# Predicci√≥n con configuraci√≥n personalizada
python scripts/predict.py \
    --weights runs/detect/train/weights/best.pt \
    --source test_images/ \
    --conf 0.3 \
    --exp-name "pred_test_v1" \
    --notes "Predicciones con confidence 0.3"
```

### 5. Ver Resultados

```bash
# Ver resumen de todos los experimentos
python scripts/view_results.py

# Ver mejor modelo
python scripts/view_results.py --best-model

# Ver √∫ltimos 5 experimentos
python scripts/view_results.py --summary --last 5
```

## üìä Hojas del Excel

### üîç Hoja "Resumen"

Vista comparativa de todos los experimentos en una sola hoja:

| Fecha | Hora | Tipo | Experimento | Modelo | √âpocas | mAP@0.5 | mAP@0.5:0.95 | Precision | Recall | F1-Score | Detecciones | Notas |
|-------|------|------|-------------|--------|--------|---------|--------------|-----------|--------|----------|-------------|-------|
| 2024-01-15 | 14:30:00 | Training | train_v1 | yolo11n.pt | 30 | 0.8542 | 0.6234 | 0.8123 | 0.7856 | 0.7988 | - | Primer modelo |
| 2024-01-15 | 15:45:00 | Evaluation | eval_v1 | train | - | 0.8521 | 0.6198 | 0.8101 | 0.7834 | 0.7966 | - | Evaluaci√≥n val |
| 2024-01-15 | 16:00:00 | Prediction | pred_test | train | - | - | - | - | - | - | 45 | Test set |

**Uso**: Ideal para comparar r√°pidamente todos los experimentos y encontrar tendencias.

### üèãÔ∏è Hoja "Training"

Detalles completos de entrenamientos:

- Configuraci√≥n del modelo
- Hiperpar√°metros (√©pocas, batch, imgsz, device)
- Duraci√≥n del entrenamiento en minutos
- M√©tricas finales (mAP, Precision, Recall, Loss)
- Ruta a los pesos guardados

**Uso**: Analizar qu√© configuraciones de entrenamiento funcionan mejor.

### üìà Hoja "Evaluation"

Resultados de evaluaciones:

- Modelo evaluado (weights path)
- Dataset y split (val/test)
- M√©tricas de rendimiento detalladas
- N√∫mero de clases detectadas
- Cantidad de visualizaciones generadas

**Uso**: Comparar el rendimiento del mismo modelo en diferentes datasets.

### üéØ Hoja "Prediction"

Historial de predicciones:

- Configuraci√≥n (confidence, IoU)
- Total de im√°genes procesadas
- Total de detecciones realizadas
- Detecciones por clase
- Directorio de salida

**Uso**: Rastrear predicciones realizadas y sus resultados.

## üîß Opciones Avanzadas

### Desactivar Excel Logging

Si no quieres guardar en Excel temporalmente:

```bash
# Sin guardar en Excel
python scripts/train.py --data-dir data/raw --epochs 15 --no-excel
python scripts/evaluate.py --weights best.pt --no-excel
python scripts/predict.py --weights best.pt --source img.jpg --no-excel
```

### Nombres de Experimentos Personalizados

```bash
# Training con nombre personalizado
python scripts/train.py \
    --data-dir data/raw \
    --epochs 30 \
    --name "yolo11n_aug_batch16" \
    --notes "Con data augmentation, batch 16"

# Evaluation con nombre personalizado
python scripts/evaluate.py \
    --weights best.pt \
    --exp-name "eval_test_set" \
    --notes "Evaluaci√≥n en test set"

# Prediction con nombre personalizado
python scripts/predict.py \
    --weights best.pt \
    --source images/ \
    --exp-name "pred_production" \
    --notes "Predicciones en producci√≥n"
```

### An√°lisis Detallado

```bash
# Ver solo entrenamientos
python scripts/view_results.py --training

# Ver solo evaluaciones
python scripts/view_results.py --evaluation

# Ver solo predicciones
python scripts/view_results.py --prediction

# Comparar experimentos con estad√≠sticas
python scripts/view_results.py --compare

# Exportar a CSV
python scripts/view_results.py --export results/mi_analisis.csv
```

## üíª Uso Program√°tico

Puedes usar el logger directamente en tus propios scripts:

```python
from scripts.excel_logger import ExcelLogger

# Crear logger
logger = ExcelLogger("results/experiment_results.xlsx")

# Registrar entrenamiento
logger.log_training(
    experiment_name="mi_experimento",
    model="yolo11n.pt",
    dataset="data/raw",
    epochs=30,
    batch=16,
    imgsz=640,
    device="cuda",
    duration_minutes=45.5,
    best_map50=0.85,
    best_map50_95=0.65,
    best_precision=0.82,
    best_recall=0.78,
    final_loss=0.12,
    weights_path="runs/detect/train/weights/best.pt",
    notes="Experimento con nuevos datos"
)

# Registrar evaluaci√≥n
logger.log_evaluation(
    experiment_name="eval_mi_modelo",
    weights_path="runs/detect/train/weights/best.pt",
    dataset="data/raw",
    split="val",
    device="cuda",
    precision=0.82,
    recall=0.78,
    map50=0.85,
    map50_95=0.65,
    classes_detected=3,
    notes="Evaluaci√≥n en validation set"
)

# Registrar predicci√≥n
logger.log_prediction(
    experiment_name="pred_produccion",
    weights_path="runs/detect/train/weights/best.pt",
    source="images/produccion/",
    confidence=0.25,
    iou=0.7,
    device="cuda",
    total_images=100,
    total_detections=450,
    class_counts={"objeto_a": 200, "objeto_b": 250},
    output_dir="runs/predict/produccion",
    notes="Predicciones en ambiente de producci√≥n"
)

# Obtener mejor modelo
best_model = logger.get_best_model(metric="mAP@0.5")
print(f"Mejor modelo: {best_model['Experimento']}")
print(f"mAP@0.5: {best_model['mAP@0.5']}")

# Obtener DataFrame con todos los resultados
df = logger.get_summary_dataframe()
print(df.head())

# Filtrar por tipo de experimento
df_training = df[df["Tipo"] == "Training"]
print(f"Total entrenamientos: {len(df_training)}")
```

## üß™ Probar el Sistema

Ejecuta el script de prueba para generar datos de ejemplo:

```bash
# Generar datos de prueba (5 de cada tipo)
python scripts/test_excel_logger.py

# Generar m√°s datos
python scripts/test_excel_logger.py --num-train 10 --num-eval 10 --num-predict 10

# Usar archivo de prueba diferente
python scripts/test_excel_logger.py --excel-path results/test.xlsx

# Limpiar y empezar de nuevo
python scripts/test_excel_logger.py --clean
```

Luego visualiza los resultados de prueba:

```bash
python scripts/view_results.py --excel-path results/test_experiment_results.xlsx
```

## üìà Interpretaci√≥n de M√©tricas

### mAP (Mean Average Precision)

- **mAP@0.5**: Precisi√≥n promedio con umbral de IoU de 0.5
  - ‚â• 0.9: Excelente
  - 0.7-0.9: Bueno
  - 0.5-0.7: Aceptable
  - < 0.5: Requiere mejoras

- **mAP@0.5:0.95**: Promedio de mAP desde IoU 0.5 hasta 0.95
  - M√©trica m√°s estricta y realista
  - T√≠picamente 30-40% menor que mAP@0.5

### Precision y Recall

- **Precision**: De todas las detecciones, ¬øcu√°ntas son correctas?
  - Alta precision = Pocos falsos positivos
  - Baja precision = Muchos falsos positivos

- **Recall**: De todos los objetos reales, ¬øcu√°ntos detectamos?
  - Alto recall = Pocos falsos negativos
  - Bajo recall = Muchos falsos negativos

### F1-Score

- Media arm√≥nica entre Precision y Recall
- Balance entre ambas m√©tricas
- √ötil cuando quieres optimizar ambas simult√°neamente

## üí° Mejores Pr√°cticas

### 1. Nombres Descriptivos

```bash
# ‚ùå Malo
python scripts/train.py --data-dir data/raw --epochs 15

# ‚úÖ Bueno
python scripts/train.py \
    --data-dir data/raw \
    --epochs 15 \
    --name "yolo11n_baseline_20240115" \
    --notes "Baseline sin augmentation para comparaci√≥n"
```

### 2. Documentar Cambios

Usa el campo `--notes` para documentar:
- Cambios en el dataset
- Modificaciones de hiperpar√°metros
- Experimentos A/B
- Observaciones importantes

```bash
python scripts/train.py \
    --data-dir data/raw \
    --epochs 30 \
    --notes "Aumentado rotation=15deg, flip=horizontal, brightness=0.2"
```

### 3. Versionado de Experimentos

```bash
# Versi√≥n 1: Baseline
python scripts/train.py --name "v1_baseline" --notes "Sin augmentation"

# Versi√≥n 2: Con augmentation
python scripts/train.py --name "v2_augmented" --notes "Con data augmentation"

# Versi√≥n 3: M√°s √©pocas
python scripts/train.py --name "v3_more_epochs" --epochs 50 --notes "50 √©pocas"
```

### 4. Backup Regular

```bash
# Hacer backup del Excel
cp results/experiment_results.xlsx results/backup_$(date +%Y%m%d).xlsx

# O usar script automatizado
#!/bin/bash
BACKUP_DIR="results/backups"
mkdir -p $BACKUP_DIR
cp results/experiment_results.xlsx \
   $BACKUP_DIR/backup_$(date +%Y%m%d_%H%M%S).xlsx
echo "Backup creado en $BACKUP_DIR"
```

### 5. An√°lisis Peri√≥dico

```bash
# Cada semana, revisa tus experimentos
python scripts/view_results.py --best-model
python scripts/view_results.py --compare

# Exporta para an√°lisis m√°s profundo
python scripts/view_results.py --export results/weekly_report.csv
```

## üîç Casos de Uso

### Caso 1: Optimizaci√≥n de Hiperpar√°metros

```bash
# Probar diferentes batch sizes
python scripts/train.py --batch 8 --name "exp_batch8" --notes "batch=8"
python scripts/train.py --batch 16 --name "exp_batch16" --notes "batch=16"
python scripts/train.py --batch 32 --name "exp_batch32" --notes "batch=32"

# Comparar resultados
python scripts/view_results.py --training
```

### Caso 2: Comparaci√≥n de Modelos

```bash
# Entrenar diferentes modelos
python scripts/train.py --model yolo11n.pt --name "exp_yolo11n"
python scripts/train.py --model yolo11s.pt --name "exp_yolo11s"
python scripts/train.py --model yolov8n.pt --name "exp_yolov8n"

# Encontrar el mejor
python scripts/view_results.py --best-model
```

### Caso 3: Evaluaci√≥n en M√∫ltiples Datasets

```bash
# Evaluar en validation y test
python scripts/evaluate.py --weights best.pt --split val --exp-name "eval_val"
python scripts/evaluate.py --weights best.pt --split test --exp-name "eval_test"

# Comparar resultados
python scripts/view_results.py --evaluation
```

## ‚ùì Soluci√≥n de Problemas

### Problema: "Excel logger no disponible"

**Soluci√≥n**:
```bash
pip install pandas openpyxl
```

### Problema: El archivo Excel no se actualiza

**Causas posibles**:
1. El archivo est√° abierto en Excel ‚Üí Ci√©rralo
2. Permisos insuficientes ‚Üí Verifica permisos en `results/`
3. Disco lleno ‚Üí Libera espacio

**Soluci√≥n temporal**:
```bash
python scripts/train.py --no-excel  # Entrenar sin guardar en Excel
```

### Problema: M√©tricas aparecen como 0 o vac√≠as

**Causas**:
- El entrenamiento no se complet√≥ correctamente
- No existe el archivo `results.csv` en el directorio del experimento
- Error al leer las m√©tricas de YOLO

**Soluci√≥n**:
1. Verifica que el entrenamiento se complet√≥ sin errores
2. Revisa las notas en el Excel para m√°s detalles
3. Busca el archivo `results.csv` en `runs/detect/train*/`

### Problema: "Permission denied" al escribir Excel

**Soluci√≥n**:
```bash
# Cambiar permisos del directorio
chmod -R 755 results/

# O crear nuevo archivo
python scripts/train.py --excel-path results/nuevo_results.xlsx
```

## üìö Referencias

- [Documentaci√≥n Ultralytics YOLO](https://docs.ultralytics.com/)
- [Pandas Excel Writer](https://pandas.pydata.org/docs/reference/api/pandas.ExcelWriter.html)
- [OpenPyXL Documentation](https://openpyxl.readthedocs.io/)

## ü§ù Contribuir

Si encuentras bugs o quieres agregar funcionalidades:

1. Reporta el issue con descripci√≥n detallada
2. Prop√≥n mejoras con ejemplos de uso
3. Comparte tus an√°lisis y mejores pr√°cticas

## üìù Changelog

### v1.0.0 (2024)
- ‚ú® Sistema inicial de logging en Excel
- ‚ú® 4 hojas: Resumen, Training, Evaluation, Prediction
- ‚ú® Script de visualizaci√≥n de resultados
- ‚ú® Script de prueba con datos de ejemplo
- ‚ú® Formato autom√°tico con colores
- ‚ú® Identificaci√≥n del mejor modelo
- ‚ú® Exportaci√≥n a CSV

---

**¬°Listo!** Ya puedes empezar a registrar y comparar tus experimentos de manera profesional. üöÄ

Para preguntas o soporte, revisa la documentaci√≥n en `results/README.md` o ejecuta:

```bash
python scripts/view_results.py --help
python scripts/test_excel_logger.py --help
```
