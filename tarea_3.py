# -*- coding: utf-8 -*-
"""Tarea_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VmUKzy7FGkZv67k6VVhQZnYKEwsMWS1w

## Instalar dependencias
"""

!pip install Pillow numpy opencv-python==4.11.0.86

"""## Descomprimir conjunto de datos"""

!gdown --folder https://drive.google.com/drive/folders/1-w8GNtkpS2tNjKl-AFnN2XkA881zPh5p?usp=sharing

# @title
# Usar cualquiera de los dos o un conjunto propio (proyecto) que cumpla los requisitos se√±alados en el documento de la tarea.

# !unzip /content/Dataset/Weapons.zip -d /content/dataset

!unzip /content/Dataset/Drone-Bird.zip -d /content/dataset

"""## Importar librer√≠as"""

import os
import random
import shutil
from PIL import Image, ImageEnhance
import numpy as np
import yaml
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from collections import Counter, defaultdict

"""## An√°lisis de Conjunto de Datos"""

PATH_BASE = '/content/dataset/'
DATA_YAML_PATH = os.path.join(PATH_BASE, 'data.yaml')
LABELS_PATH = os.path.join(PATH_BASE, 'train/labels')
IMAGES_PATH = os.path.join(PATH_BASE, 'train/images')

AUGMENTED_IMAGES_DIR = IMAGES_PATH
AUGMENTED_LABELS_DIR = LABELS_PATH

with open(DATA_YAML_PATH, 'r') as f:
    data_yaml = yaml.safe_load(f)

class_names = data_yaml['names']
class_names_map = {i: name for i, name in enumerate(class_names)}
print(f"Clases detectadas: {class_names_map}")

def analizar_dataset(labels_path):
    """
    Retorna:
    1. Conteo total por clase.
    2. Un mapa de {ruta_imagen: [lista_de_clases_en_imagen]}.
    """
    conteo = Counter()
    img_composition = defaultdict(list)

    for filename in os.listdir(labels_path):
        if filename.endswith('.txt'):
            filepath = os.path.join(labels_path, filename)
            img_name = os.path.splitext(filename)[0]

            # Asumimos que la imagen tiene extensi√≥n jpg o png, buscamos cu√°l existe
            img_file = None
            for ext in ['.jpg', '.png', '.jpeg']:
                if os.path.exists(os.path.join(IMAGES_PATH, img_name + ext)):
                    img_file = img_name + ext
                    break

            if not img_file: continue

            with open(filepath, 'r') as f:
                classes_in_file = []
                for line in f:
                    try:
                        class_id = int(line.strip().split()[0])
                        conteo[class_id] += 1
                        classes_in_file.append(class_id)
                    except:
                        continue
                if classes_in_file:
                    img_composition[img_file] = classes_in_file

    return conteo, img_composition

conteo_inicial, mapa_imagenes = analizar_dataset(LABELS_PATH)

# Identificar Clase Mayoritaria y Minoritarias autom√°ticamente
if not conteo_inicial:
    raise ValueError("No se encontraron etiquetas. Revisa la ruta.")

id_clase_mayoritaria = max(conteo_inicial, key=conteo_inicial.get)
count_mayoritaria = conteo_inicial[id_clase_mayoritaria]

print(f"\n--- Breve An√°lisis ---")
print(f"Clase Mayoritaria: ID {id_clase_mayoritaria} ({class_names_map.get(id_clase_mayoritaria)}) -> {count_mayoritaria} instancias.")

total_instancias_originales = sum(conteo_inicial.values())
LIMITE_AUMENTACION = int(total_instancias_originales * 0.25)

print(f"Total instancias originales: {total_instancias_originales}")
print(f"L√≠mite de aumentaci√≥n (25%): M√°ximo {LIMITE_AUMENTACION} nuevas instancias permitidas en total.")

df = pd.DataFrame(conteo_inicial.items(), columns=['Class_ID', 'Count'])
df['Class_Name'] = df['Class_ID'].map(class_names_map)
df = df.sort_values('Class_ID')

plt.figure(figsize=(10, 6))
sns.barplot(x='Class_Name', y='Count', data=df)
plt.title('Distribuci√≥n de Clases')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.axhline(y=count_mayoritaria, color='r', linestyle='--', label='Clase Mayoritaria Original')
plt.legend()
plt.show()

"""### **Paso 1: Preparaci√≥n para la Aumentaci√≥n de Datos**

Primero, definimos las rutas donde se guardar√°n nuestras im√°genes y etiquetas aumentadas. En este caso, las guardaremos en los directorios originales (`train/images` y `train/labels`).
"""

AUGMENTED_IMAGES_DIR = os.path.join(PATH_BASE, 'train/images')
AUGMENTED_LABELS_DIR = os.path.join(PATH_BASE, 'train/labels')

print(f"Las im√°genes aumentadas se guardar√°n en: {AUGMENTED_IMAGES_DIR}")
print(f"Las etiquetas aumentadas se guardar√°n en: {AUGMENTED_LABELS_DIR}")

"""### **Paso 2: Funci√≥n para Rotar Cajas Delimitadoras (Bounding Boxes)**

Cuando rotamos una imagen, tambi√©n necesitamos rotar las cajas delimitadoras que indican d√≥nde est√°n los objetos. Esta funci√≥n toma las coordenadas de una caja (en p√≠xeles) y el √°ngulo de rotaci√≥n, y calcula c√≥mo se ver√≠a la nueva caja despu√©s de rotar la imagen. Es un poco compleja porque las rotaciones pueden cambiar el tama√±o de la imagen y la forma de la caja.
"""

def rotate_bbox(x_min, y_min, x_max, y_max, image_width, image_height, angle):
    corners = np.array([[x_min, y_min], [x_max, y_min], [x_min, y_max], [x_max, y_max]])
    original_center_x, original_center_y = image_width / 2, image_height / 2

    temp_img = Image.new('RGB', (image_width, image_height))
    rotated_temp = temp_img.rotate(angle, expand=True)
    new_w, new_h = rotated_temp.size

    rad_angle = np.deg2rad(angle)
    cos_a, sin_a = np.cos(rad_angle), np.sin(rad_angle)

    new_corners = []
    for x, y in corners:
        x_t, y_t = x - original_center_x, y - original_center_y
        x_r = x_t * cos_a - y_t * sin_a
        y_r = x_t * sin_a + y_t * cos_a
        new_corners.append([x_r + new_w/2, y_r + new_h/2])

    new_corners = np.array(new_corners)
    return np.min(new_corners[:,0]), np.min(new_corners[:,1]), np.max(new_corners[:,0]), np.max(new_corners[:,1]), new_w, new_h

"""### **Paso 3: Funci√≥n para Aplicar Aumentaciones Aleatorias**

Esta es la funci√≥n principal de aumentaci√≥n. Toma una imagen y sus cajas delimitadoras (en formato YOLO normalizado) y le aplica una serie de transformaciones aleatorias. Despu√©s de cada transformaci√≥n, se asegura de que las cajas delimitadoras sigan siendo correctas y v√°lidas.
"""

def apply_random_augmentation(image, boxes, w, h):
    aug_img = image.copy()
    aug_boxes = [b[:] for b in boxes]
    curr_w, curr_h = w, h

    # Flip Horizontal
    if random.random() < 0.5:
        aug_img = aug_img.transpose(Image.FLIP_LEFT_RIGHT)
        for i in range(len(aug_boxes)):
            aug_boxes[i][1] = 1 - aug_boxes[i][1]

    # Rotaci√≥n leve
    angle = random.uniform(-10, 10)
    if abs(angle) > 1:
        temp_img = Image.new('RGB', (curr_w, curr_h))
        new_w, new_h = temp_img.rotate(angle, expand=True).size
        aug_img = aug_img.rotate(angle, expand=True)

        new_boxes = []
        for box in aug_boxes:
            cid, xc, yc, bw, bh = box
            x_px, y_px = xc * curr_w, yc * curr_h
            w_px, h_px = bw * curr_w, bh * curr_h
            x1, y1 = x_px - w_px/2, y_px - h_px/2
            x2, y2 = x_px + w_px/2, y_px + h_px/2

            nx1, ny1, nx2, ny2, _, _ = rotate_bbox(x1, y1, x2, y2, curr_w, curr_h, angle)

            n_xc = ((nx1 + nx2)/2) / new_w
            n_yc = ((ny1 + ny2)/2) / new_h
            n_bw = (nx2 - nx1) / new_w
            n_bh = (ny2 - ny1) / new_h

            # Validar l√≠mites
            if 0 < n_bw <= 1 and 0 < n_bh <= 1:
                new_boxes.append([cid, np.clip(n_xc,0,1), np.clip(n_yc,0,1), n_bw, n_bh])

        aug_boxes = new_boxes
        curr_w, curr_h = new_w, new_h

    # Color/Brillo
    if random.random() < 0.5:
        aug_img = ImageEnhance.Brightness(aug_img).enhance(random.uniform(0.7, 1.3))

    return aug_img, aug_boxes

"""### **Paso 4: Bucle Principal de Aumentaci√≥n de Datos**

"""

instancias_generadas_total = 0
conteo_actual = conteo_inicial.copy()
generated_filenames = set()

print("\nIniciando proceso de balanceo...")

clases_a_aumentar = [c for c in conteo_actual if c != id_clase_mayoritaria]

for id_clase in clases_a_aumentar:
    if instancias_generadas_total >= LIMITE_AUMENTACION:
        print("Se alcanz√≥ el l√≠mite global de seguridad del 25%. Deteniendo.")
        break

    objetivo = count_mayoritaria
    actual = conteo_actual[id_clase]
    faltan = objetivo - actual

    if faltan <= 0:
        continue

    print(f"\nProcesando Clase {class_names_map[id_clase]} (Faltan aprox: {faltan})")

    candidatos = [img for img, clases in mapa_imagenes.items() if id_clase in clases]

    candidatos.sort(key=lambda x: (id_clase_mayoritaria in mapa_imagenes[x], len(mapa_imagenes[x])))

    if not candidatos:
        print(f"No hay im√°genes base para la clase {id_clase}. Saltando.")
        continue

    # Generamos im√°genes
    idx_candidato = 0
    while conteo_actual[id_clase] < objetivo:

        # Checkeo de max 25% de aumentaci√≥n
        if instancias_generadas_total >= LIMITE_AUMENTACION:
            print("L√≠mite de aumentaci√≥n del 25% alcanzado durante el proceso.")
            break

        img_filename = candidatos[idx_candidato % len(candidatos)]
        idx_candidato += 1

        # Preparar rutas
        src_img_path = os.path.join(IMAGES_PATH, img_filename)
        src_lbl_path = os.path.join(LABELS_PATH, os.path.splitext(img_filename)[0] + '.txt')

        try:
            # Leer imagen y etiquetas
            img = Image.open(src_img_path).convert('RGB')
            w, h = img.size
            boxes = []
            with open(src_lbl_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        boxes.append([int(parts[0])] + [float(p) for p in parts[1:]])

            # Aplicar aumentaci√≥n
            aug_img, aug_boxes = apply_random_augmentation(img, boxes, w, h)

            if not aug_boxes: continue

            # Guardar
            suffix = random.randint(10000, 99999)
            new_base = f"{os.path.splitext(img_filename)[0]}_aug_{suffix}"

            aug_img.save(os.path.join(AUGMENTED_IMAGES_DIR, new_base + '.jpg'))

            with open(os.path.join(AUGMENTED_LABELS_DIR, new_base + '.txt'), 'w') as f:
                for box in aug_boxes:
                    f.write(f"{int(box[0])} {box[1]:.6f} {box[2]:.6f} {box[3]:.6f} {box[4]:.6f}\n")

            instancias_agregadas_en_imagen = 0
            for box in aug_boxes:
                cid = int(box[0])
                conteo_actual[cid] += 1
                instancias_agregadas_en_imagen += 1

            instancias_generadas_total += instancias_agregadas_en_imagen

            if idx_candidato % 50 == 0:
                print(f"   -> Actual: {conteo_actual[id_clase]} / Meta: {objetivo} (Global agregadas: {instancias_generadas_total})")

        except Exception as e:
            print(f"Error procesando {img_filename}: {e}")
            continue

print(f"\n=== FINALIZADO ===")
print(f"Total instancias agregadas: {instancias_generadas_total}")
print("Conteo final estimado:", dict(conteo_actual))

"""## An√°lisis de conjunto de entrenamiento luego de realizar aumentaci√≥n de datos"""

df = pd.DataFrame(conteo_actual.items(), columns=['Class_ID', 'Count'])
df['Class_Name'] = df['Class_ID'].map(class_names_map)
df = df.sort_values('Class_ID')

plt.figure(figsize=(10, 6))
sns.barplot(x='Class_Name', y='Count', data=df)
plt.title('Distribuci√≥n de Clases Post-Aumentaci√≥n')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.axhline(y=count_mayoritaria, color='r', linestyle='--', label='Objetivo Original')
plt.legend()
plt.show()

"""## Entrenamiento con YOLO

## Instalar librer√≠as necesarias
"""

!pip install ultralytics opencv-python==4.11.0.86 torch torchvision

"""## Librer√≠as a utilizar"""

from ultralytics import YOLO
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2 as cv
import torch
import os

"""## Entrenar modelo

### Evaluar Uso de CPU/GPU
"""

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("GPU disponible. Usando:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("No hay GPU disponible. Usando CPU.")

# Cargar un modelo YOLO11n preentrenado
model = YOLO("/content/Dataset/yolo11n.pt")

train_results = model.train(
    data="/content/dataset/data.yaml",   # Ruta al archivo de configuraci√≥n del conjunto de datos
    epochs=15,          # N√∫mero de √©pocas de entrenamiento
    imgsz=640,          # Tama√±o de las im√°genes durante el entrenamiento
    device="gpu",       # Usar GPU si est√° disponible
)

"""## Evaluar Modelo"""

# Cargar el mejor modelo
model = YOLO("/content/runs/detect/train4/weights/best.pt")

# Evaluar el modelo
metrics = model.val(
    device=0,
    plots=True,
    visualize=True
)

# Ruta de la imagen espec√≠fica que quieres mostrar
img_path = '/content/runs/detect/val/visualizations/165_JPEG_jpg.rf.4306d1c220e917659ef0d96182ff4682.jpg'

# Verificar si el archivo de imagen existe
if os.path.exists(img_path):
    img = mpimg.imread(img_path)

    # Mostrar la imagen sin bordes blancos
    fig, ax = plt.subplots(figsize=(img.shape[1]/100, img.shape[0]/100), dpi=100) # Ajustar tama√±o de figura
    ax.imshow(img)
    ax.set_title(os.path.basename(img_path)) # Usar el nombre del archivo como t√≠tulo
    ax.axis('off') # Ocultar ejes

    # Eliminar el espacio en blanco alrededor de la imagen
    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)
    plt.margins(0,0)
    ax.xaxis.set_major_locator(plt.NullLocator())
    ax.yaxis.set_major_locator(plt.NullLocator())

    plt.show()
else:
    print(f"Error: No se encontr√≥ la imagen en la ruta: {img_path}")

image_path = '/content/runs/detect/val/BoxF1_curve.png'

if os.path.exists(image_path):
    img = mpimg.imread(image_path)
    plt.figure(figsize=(10, 6))
    plt.imshow(img)
    plt.title('BoxF1 Curve')
    plt.axis('off')
    plt.show()
else:
    print(f"Error: No se encontr√≥ la imagen en la ruta: {image_path}")

image_path = '/content/runs/detect/val/BoxPR_curve.png'

if os.path.exists(image_path):
    img = mpimg.imread(image_path)
    plt.figure(figsize=(10, 6))
    plt.imshow(img)
    plt.title('Box Precision Recall Curve')
    plt.axis('off')
    plt.show()
else:
    print(f"Error: No se encontr√≥ la imagen en la ruta: {image_path}")

image_path = '/content/runs/detect/val/confusion_matrix.png'

if os.path.exists(image_path):
    img = mpimg.imread(image_path)
    plt.figure(figsize=(8, 8))
    plt.imshow(img)
    plt.title('Matriz de Confusi√≥n')
    plt.axis('off')
    plt.show()
else:
    print(f"Error: No se encontr√≥ la imagen en la ruta: {image_path}")

"""## Predicci√≥n con el mejor modelo"""

# Cargar modelo YOLO pre-entrenado
model = YOLO('/content/runs/detect/train4/weights/best.pt')

# Ruta de la imagen
image_path = '/content/Drone.jpeg'

# Realizar la detecci√≥n
results = model(image_path)

print("Resultados: ", results)

# Mostrar resultados
for r in results:
    # Acceder a las cajas delimitadoras y sus puntuaciones de confianza
    boxes = r.boxes
    for box in boxes:
        # box.xyxy contiene las coordenadas [x1, y1, x2, y2]
        # box.conf contiene la puntuaci√≥n de confianza
        # box.cls contiene el √≠ndice de la clase
        print(f"Bounding Box: {box.xyxy}, Confidence: {box.conf}, Class: {model.names[int(box.cls)]}")

    im_array = r.plot()  # Imagen con cajas dibujadas (BGR)

    # Convertir de BGR (OpenCV) a RGB (para matplotlib)
    im_rgb = cv.cvtColor(im_array, cv.COLOR_BGR2RGB)

    # Mostrar con matplotlib
    plt.figure(figsize=(8, 8))
    plt.imshow(im_rgb)
    plt.axis('off')
    plt.title('Detecci√≥n de objetos')
    plt.show()

    # Guardar el resultado
    cv.imwrite('resultado_imagen.jpg', im_array)

"""## Conclusiones
Estas conclusiones las hago en base a mi Tarea N¬∞2 ya que use el mismo dataset.

# Comparativa de Rendimiento: Impacto de la Aumentaci√≥n de Datos

## Contexto del Experimento
El modelo original presentaba un desbalance de clases significativo, donde la clase **Drone** (3185 instancias) superaba a la clase **Bird** (2135 instancias). Para mitigar el posible sesgo hacia la clase mayoritaria, se entren√≥ una nueva versi√≥n aplicando una **aumentaci√≥n de datos del 25% exclusivamente a la clase Birds**, buscando equilibrar la representatividad durante el entrenamiento.

## Tabla Comparativa de M√©tricas

| M√©trica | Modelo Base (Sin Aug) | Modelo Aumentado (+25% Birds) | An√°lisis de la Evoluci√≥n |
| :--- | :---: | :---: | :--- |
| **mAP@0.5 (Birds)** | 0.990 | **0.992** | üü¢ **Mejora (+0.002)**. La precisi√≥n media mejor√≥ ligeramente, acerc√°ndose a la perfecci√≥n en detecci√≥n est√°ndar. |
| **mAP@0.5 (Drones)** | 0.983 | **0.983** | ‚ö™ **Estabilidad**. El rendimiento en la clase mayoritaria se mantuvo id√©ntico, sin efectos negativos colaterales. |
| **mAP@0.5 (All Classes)**| 0.987 | **0.987** | ‚ö™ El promedio global se mantiene robusto. |
| **mAP@50-95 (Birds)** | 0.794 | **0.804** | üåü **Resultado Destacado**. Un 80.4% en la m√©trica estricta supera ampliamente a la clase Drones, validando la calidad de la aumentaci√≥n. |
| **mAP@50-95 (Drones)**| **0.747** | 0.744 | La clase mayoritaria tiene un ajuste de caja (bounding box) inferior al de la clase aumentada. |
| **Max F1-Score** | 0.97 (@ conf 0.524) | **0.97 (@ conf 0.556)** | üü¢ **Mayor Confianza**. El pico de rendimiento se alcanza con un umbral de confianza m√°s alto (+0.032), lo que indica un modelo m√°s decidido. |
| **Precisi√≥n (Birds)** | **1.00** | 0.985 | üìâ Ligero ajuste. Al entrenar con datos m√°s dif√≠ciles (aumentados), el modelo reduce levemente su precisi√≥n pura para ganar generalizaci√≥n. |
| **Recall (Birds)** | 0.960 | **0.962** | El modelo es capaz de recuperar el 96.2% de todas las aves presentes en el set de validaci√≥n. |

## An√°lisis de Resultados (A completar tras entrenamiento)

### 3. Conclusi√≥n General
- ¬øPara que sirve en este caso aplicar aumentaci√≥n de datos?:
Al existir un desbalance en la cantidad de instancias de cada clase, pues esto causa una confusi√≥n en el modelo, es por eso que debemos realizar aumentaci√≥n para que el modelo sea capaz de indentificar y tener parametros claro de comparacion.

- Si el conjunto de datos no hubiese sido aumentado a la mayor clase, ¬ørendir√≠a de mejor o peor
forma el modelo?:
Rendir√≠a pero debido a que no detectar√≠a de igual forma los birds, tendria menor porcentaje de metricas como Precision, mAP@0.5, F1-Score M√°ximo, el umbral √≥ptimo ser√≠a menor y la matriz de confusi√≥n tendria peores resultados.

- Una vez aumentado los datos, ¬øel modelo presenta buenos resultados en base al log que deja
el entrenamiento? Si se aumentan las √©pocas, ¬øMejorar√° el modelo?.
Si totalmente mejorarp√°, teniendo en cuenta el anterior sin aumentacion y usando la misma cantidad de epocas, pues obviamente subir√≠a aun mas los resultados de las metricas.
Lo que si, la metrica que bajo es la de mAP@50-95 (Drones). Fuera de eso, si aumentamos epocas debe subir aun m√°s.
"""